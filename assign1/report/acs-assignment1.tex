% !TEX TS-program = pdflatex
\documentclass[11pt,a4paper,english]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[obeyspaces, hyphens]{url}
\usepackage[top=4cm, bottom=4cm, left=3cm, right=3cm]{geometry}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{mdwlist}
\usepackage{fancyhdr}
\usepackage{cite}
\usepackage{amsmath}
\usepackage[normalem]{ulem} % ulem enables strikethrough and more, but makes
                            % \emph underline by default :(
\usepackage{babel}
\usepackage{fancyvrb}
\usepackage{verbatimbox}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{minted}
\usepackage{xcolor}
\usepackage{csquotes}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{array}
\usepackage{lmodern} % better font
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{hyperref} % always load hyper ref in the end
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\newcommand*\justify{%
  \fontdimen2\font=0.4em% interword space
  \fontdimen3\font=0.2em% interword stretch
  \fontdimen4\font=0.1em% interword shrink
  \fontdimen7\font=0.1em% extra space
  \hyphenchar\font=`\-% allowing hyphenation
}

\lstset{
    frame=lrtb,
    captionpos=b,
    belowskip=0pt
}

\captionsetup[listing]{aboveskip=5pt,belowskip=\baselineskip}

\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO: }#1}}

%\definecolor{lightgray}{rgb}{0.95,0.95,0.95}
%\renewcommand\listingscaption{Code}

\newcommand{\concat}{\ensuremath{+\!\!\!\!+\!\!}}

\pagestyle{fancy}
\headheight 35pt

\DefineVerbatimEnvironment{code}{Verbatim}{fontsize=\small}
\DefineVerbatimEnvironment{example}{Verbatim}{fontsize=\small}
\newcommand{\ignore}[1]{}

\hyphenation{character-ised}

\rhead{Assignment 1}
\lhead{ACS}
\begin{document}

\thispagestyle{empty} %fjerner sidetal
\hspace{6cm} \vspace{6cm}
\begin{center}
\textbf{\Huge {Advanced Computer Systems}}\\ \vspace{0.5cm}
\Large{Assignment 1}
\end{center}
\vspace{3cm}
\begin{center}
\Large{\textbf{Truls Asheim, Rasmus Wriedt Larsen, Viktor Hansen}}
\end{center}
\vspace{6.0cm}
\thispagestyle{empty}

\newpage

\section{Exercises}
\subsection{Questions 1: Fundamental Abstractions}
\begin{enumerate}
\item{
The top-level abstraction makes use of location addressed memory, i.e. an N-bit memory address mapping a byte of the address space. Each machine $m_i$ in the cluster contains $n_i$ bytes of memory and the memory is directly mapped to address ranges in the single address space in a contiguous manner. This entails that the only valid addresses of the address space are 0 through $\sum_{i=1}^{K} n_{i}$.

The naming scheme consists of issuing READ/WRITE request to a central server, which looks up what intervals of the memory map to which machines. The lookup function is implemented with a table. A name identifying the machine is returned to the client, which in turn issues the request to machine holding the requested data.

The design is scalable in the sense that adding a machine machine, $m_{K+1}$, to the array essentially means adding a table entry with the interval corresponding to the address space range in constant time. In this case the entry $([\sum_{i=1}^{K} n_{i}; \sum_{i=1}^{K+1} n_{i}], m_{K+1})$. This increases the range of valid addresses by $n_{k+1}$.

Client-machine communication is assumed to facilitate positive acknowledgments with retransmissions for requests. In the case a request can not be properly delivered, the central server or machine holding the requested data is assumed to be in an erronous state or unavailable. If the central server is down, it will not be possible}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Here we show pseudocode for the API

\todo{Write some more text}

\todo{consider if pesudocode should show timeout/throwing exception}

\begin{algorithm}[H]
\caption{READ}
\begin{algorithmic}[1]
\Procedure{READ}{\texttt{addr}}:
\State client send \texttt{addr} to central server
\State central server compute \texttt{machineID} for \texttt{addr}
\State central server send \texttt{machineID} to client
\smallskip
\State client send \texttt{addr} to \texttt{machineID}
\State machine checks if \texttt{addr} falls into address space it controls
\State machine calculates local memmory address, and reads \texttt{data}
\State machine send \texttt{data} to client
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{WRITE}
\begin{algorithmic}[1]
\Procedure{WRITE}{\texttt{addr}, \texttt{data}}:
\State client send \texttt{addr} to central server
\State central server compute \texttt{machineID} for \texttt{addr}
\State central server send \texttt{machineID} to client
\smallskip
\State client send \texttt{addr} and \texttt{data} to \texttt{machineID}
\State machine checks if \texttt{addr} falls into address space it controls
\State machine calculates local memmory address, and writes \texttt{data} to that location
\State machine sends ACK to client
\EndProcedure
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \todo{Are they atomic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \todo{assumptions, dynamic join/leave}

If a machine controlling memory for address $[i,j)$ goes down (eg. power failure),
we cannot remap those value. Doing so would violate the invariant that \texttt{READ}'ing
from an address that you issued the last successful \texttt{WRITE} to will give the same data.

\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Question 2: Techniques for Performance}

\begin{enumerate}
\item Concurrency enables us to process more than one request at once, which can
  reduce the average latency over serial execution, as all requests do not need
  to wait for a slow IO device to complete (ie disk access). However, this
  assumes the different threads do not spend too much time waiting to acquire
  locks, or even deadlocks.

\item \emph{Batching} is submitting more than one request to a latency heavy
  service, to amortize the cost of the latency and improve
  throughput. \emph{Dallying} is waiting to fill up buffers before batching
  requests, to further improve throughput, but will most likely increase
  latency.

\item Caching the results to frequent requests is a way of fast path
  optimization, as we do not have to perform the whole computation every time.
\end{enumerate}


\subsection{Question 4: RPC Semantics}

The semantics of RPC used for \texttt{acertainbookstore.com} is ``at most
once''. This means the request from the client is at most executed once on the
server side, and if any errors occur they are exposed to the client.


\subsection{Question 5: HTTP Proxy Servers}

The usual approach to using proxy servers to increase the number of simultaneous
users, is to make the proxy handle all incoming connections, and distribute the
work between ``worker'' machines (ie. by round-robin).

The current setup stored the book data directly in memory, and concurrent
modifications are handled using threads, which limits the uses to a
\emph{single} (possibly multicore) machine.

In our opinion the easiest way to enable scalability would be to move the data
into a database, that every worker machine would connect to. Then we can use a
proxy server as the entry point for HTTP requests, which forwards requests to a
\texttt{BookStoreHTTPServer} on some ``worker'' machine. This of course means
the database becomes a bottleneck, but it has greatly improved the situation
from having just one machine.\footnote{and also gives you lots of features for
  handling fault tolerance for free}.

%\bibliographystyle{plain}
%\bibliography{references}

%\section*{Appendix A}
%\subsection*{\path{src/commented-disassembly.txt}}
%\inputminted{text}{src/commented-disassembly.txt}

%\pagebreak

%\subsection*{\path{src/exploit.c}}
%\inputminted{c}{src/exploit.c}

\end{document}
